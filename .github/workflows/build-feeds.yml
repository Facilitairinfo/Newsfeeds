name: ðŸ› ï¸ Build & Scrape Feeds ðŸ”„

on:
  workflow_dispatch:
  schedule:
    # Draait om 04:00, 07:00, 08:00, 09:00, 10:00, 13:00, 16:00 en 19:00 NL tijd
    - cron: "0 2,5,6,7,8,11,14,17 * * *" # UTC tijden

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      # 1. Repo ophalen met volledige historie
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 2. Python installeren
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 3. Dependencies installeren
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 3b. Playwright browsers installeren
      - name: Install Playwright browsers
        run: playwright install --with-deps

      # 4. Altijd eerst laatste main ophalen en hard resetten
      - name: Sync with latest main
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git fetch origin main
          git reset --hard origin/main

      # 5. Patch alle configs met max_items: 5
      - name: Patch configs with max_items: 5
        run: python scripts/patch_limits.py

      # 6. Scraper draaien met retry bij 503 of andere fout
      - name: Run scraper with retry
        run: |
          run_scraper() { python scripts/scrape_all.py || return 1; }
          ATTEMPTS=0
          MAX_ATTEMPTS=3
          until run_scraper; do
            ATTEMPTS=$((ATTEMPTS+1))
            if [ "$ATTEMPTS" -ge "$MAX_ATTEMPTS" ]; then
              echo "âŒ Scraper mislukt na $ATTEMPTS pogingen."
              exit 1
            fi
            echo "âš ï¸ Fout, poging $ATTEMPTS/$MAX_ATTEMPTS â€” wacht 10s..."
            sleep 10
          done

      # 6b. Debug scraping NEN-feed
      - name: Run scraper with debug
        run: |
          mkdir -p debug
          echo "Snapshot van NEN-site ophalen..."
          curl -sL https://www.nen.nl/nieuws -o debug/nen_raw.html || echo "Snapshot mislukt"
          echo "Scraper starten..."
          python scripts/run_scraper.py --config configs/sites-nen-nieuws.yml || echo "Scraper faalde"
          echo "Bestanden in /docs:"
          ls -lah docs/
          test -f docs/sites-nen-nieuws.xml && echo "âœ… XML gegenereerd" || echo "âŒ XML ontbreekt"

      # 7. Genereer feedstatus dashboard
      - name: Genereer feedstatus dashboard
        run: python scripts/gen_feedstatus.py

      # 8. Commit en push alleen bij wijzigingen
      - name: Commit and push changes
        run: |
          git add docs/*.xml docs/feedstatus.json docs/feedonderhoud.html 2>/dev/null || true
          git commit -m "Update feeds & status [skip ci]" || echo "Geen wijzigingen in output, commit wordt overgeslagen."
          git push origin main
